<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Call for Posters</title>
    <link rel="stylesheet" href="styles/call_for_poster.css">
</head>

<body>
    <header class="header">
        <nav class="navbar">
            <ul>
                <li><a href="index.html">Overview</a></li>
                <li><a href="schedule.html">Schedule</a></li>
                <li><a href="call_for_poster.html">Call for Posters</a></li>
                <li><a href="contest.html">ML for Chip Design Contest</a></li>
                <li><a href="photos.html">Event Photos</a></li>
            </ul>
        </nav>
        <div class="title-section">
            <h1>Call for Posters</h1>
        </div>
    </header>

    <main class="content">
        <section class="poster-details">
            <!-- <h4>Call for Posters</h4> -->
            <p>Our workshop welcomes posters in the following topics:</p>
            <ul>
                <li>Graph Neural Networks for performance, power, and area (PPA) prediction and optimization for all stages of EDA pipeline, including HLS, RTL/logic synthesis, and physical designs;</li>
                <li>LLM-based code analysis for PPA prediction and optimization at all stages of EDA pipeline;</li>
                <li>Multi-modality ML models (e.g., LLM + GNN) for PPA prediction and optimization at all stages of EDA pipeline;</li>
                <li>Domain and task transfer for HLS performance prediction with new kernels and new versions of EDA tools at different stages;</li>
                <li>ML methods to optimize circuit aging and reliability;</li>
                <li>ML for design technology co-optimization (DTCO);</li>
                <li>ML for analog, mixed-signal, and RF IC designs;</li>
                <li>Reinforcement Learning for Design Space Exploration (DSE);</li>
                <li>LLM-based design generation;</li>
                <li>Active learning and importance sampling of design points;</li>
                <li>AI for compiler and code transformation;</li>
                <li>Benchmark datasets.</li>
            </ul>
        </section>

        <section class="submission-guidelines">
            <h4>Submission Guidelines</h4>
            <ul>
                <li><strong>Formatting:</strong> The submission should be a 3-page pdf file following the <a href="https://www.overleaf.com/latex/templates/neurips-2024/tpsbbrdqcmsh" target="_blank">NeurIPS 2024 template</a>. This submission should contain title, authors (affiliations and email addresses), a short abstract, background introduction, and a summary of the proposed problem, methods, and main results. References are excluded from the page limit.</li>
                <li><strong>Originality:</strong> The submission is encouraged to be unpublished or recently accepted work due to the forward-looking nature of the workshop.</li>
                <li><strong>Poster presentation:</strong> All accepted submissions will be presented as posters on the workshop day.</li>
                <li><strong>Submission link:</strong> Please submit through <a href="https://forms.gle/7JZMXL1pmGdddYJh7" target="_blank">this submission link</a>.</li>
                <li><strong>Submission deadline:</strong> November 4, 2024, 11:59 PM UTC-12 (AoE)</li>
                <li><strong>Notification date:</strong> November 10, 2024 (or earlier, as soon as we finish reviewing)</li>
                <li><strong>Late submission deadline:</strong> November 11, 2024, 11:59 PM UTC-12 (AoE) (we will review quickly after it)</li>
            </ul>
        </section>

        <section class="accepted-posters">
            <h4>Accepted Posters</h4>
            <ul>
                <li>"<strong><a href="https://drive.google.com/file/d/1OdoGAPL8dDkAdL5lEIl4r2ebWnX4OnhI/view?usp=sharing" target="_blank">Hybrid Graph Representation and Learning Framework for High-Level Synthesis Design Space Exploration</a></strong>," Pouya Taghipour, Eric Granger, Yves Blaquiere (École de Technologie Supérieure). ID: 1</li>
                <li>"<strong><a href="https://drive.google.com/file/d/1_Sbxqfjq2Y0_JjXgkGSOKvIjSvEMpu9S/view?usp=sharing" target="_blank">Hierarchical Mixture of Experts: Generalizable Learning for High-Level Synthesis</a></strong>," Weikai Li, Ding Wang, Zijian Ding, Atefeh Sohrabizadeh, Zongyue Qin, Jason Cong, Yizhou Sun (University of California - Los Angeles). ID: 2</li>
                <li>"<strong><a href="https://drive.google.com/file/d/15nTQ3XDjxfIpx_yd_fMn1nq7_0PRCHxl/view?usp=sharing" target="_blank">CTGAN-Bandit: A Conditional Tabular GAN Model Leveraging Upper Confidence Bound Estimators for Hardware Design Verification</a></strong>," Lorenzo Ferretti, Surya Teja Bandlamudi, Nihar Athreyas, Michael Yan, Vikram Narayan, Samir Mittal (Micron Technology). ID: 3</li>
                <li>"<strong><a href="https://drive.google.com/file/d/1X-h5r1A8y-kcaWlYGauOTnYXfBEomx_E/view?usp=sharing" target="_blank">AnalogCoder: Analog Circuit Design via Training-Free Code Generation</a></strong>," Yao Lai<sup>1</sup>, Sungyoung Lee<sup>2</sup>, Guojin Chen<sup>3</sup>, Souradip Poddar<sup>2</sup>, Mengkang Hu<sup>1</sup>, David Z. Pan<sup>2</sup>, Ping Luo<sup>1</sup> (<sup>1</sup>The University of Hong Kong, <sup>2</sup>The University of Texas at Austin, <sup>3</sup>The Chinese University of Hong Kong). ID: 4</li>
                <li>"<strong><a href="https://drive.google.com/file/d/1Koo9TaM3HiciDY_tgFb6OANg99NyDAJq/view?usp=sharing" target="_blank">FloorSet: Benchmark for AI-driven Floorplanning</a></strong>," Uday Mallappa, Hesham Mostafa, Mikhail Galkin, Mariano Phielipp, Somdeb Majumdar (Intel Labs). ID: 5</li>
                <li>"<strong><a href="https://drive.google.com/file/d/1dl-0Up_O-vgEdNPX1_d-Cox9IJ7eDJd8/view?usp=sharing" target="_blank">Inverse Patterning Technology with Transformer-Based Optimization</a></strong>," Sooyong Lee<sup>1</sup>, Guandao Yang<sup>2</sup>, Suyeon Choi<sup>2</sup>, Seongtae Jeong<sup>1</sup>, Gordon Wetzstein<sup>2</sup> (<sup>1</sup>Samsung Electronics, <sup>2</sup>Stanford University). ID: 6</li>
                <li>"<strong><a href="https://drive.google.com/file/d/1k_CzqE9jRk8o397K2dsIah0Ufke_buDX/view?usp=sharing" target="_blank">Coverage Closure with an Agentic LLM Workflow</a></strong>," Ximin Shan, Rahul Krishnamurthy, Jayanth Raman, Nick Cheng, Vikram Narayan, Samir Mittal (Micron Technology). ID: 7</li>
                <li>"<strong><a href="https://drive.google.com/file/d/1FaRPdZIr11k3hCeD7hxXyE9d9lluYENX/view?usp=sharing" target="_blank">AI to Reduce Wasted Time in FPGA Routing</a></strong>," Andrew David Gunter, Steven Wilton (The University of British Columbia). ID: 8</li>
                <li>"<strong><a href="https://drive.google.com/file/d/1uj3KKGYwhiXL3xWgi0EzJeW6YwzTpJMw/view?usp=sharing" target="_blank">Deep Learning Enabled Design of RF/mmWave Circuits</a></strong>," Emir Ali Karahan<sup>1</sup>, Jonathan Zhou<sup>1</sup>, Zheng Liu<sup>2</sup>, Kaushik Sengupta<sup>1</sup> (<sup>1</sup>Princeton University, <sup>2</sup>Texas Instruments). ID: 9</li>
                <li>"<strong><a href="https://drive.google.com/file/d/1DGDR8BNx2aHF2WdYue_7inyjmzUpeWRy/view?usp=sharing" target="_blank">Multi-Objective Bayesian Optimization for Efficient HDnn-PIM Software-Hardware Co-Design with Metric Constraints</a></strong>," Chien-Yi Yang<sup>1</sup>, Tim Chen<sup>1</sup>, Minxuan Zhou<sup>2</sup>, Flavio Ponzina<sup>1</sup>, Dongxia Wu<sup>1</sup>, Raid Ayoub<sup>3</sup>, Pietro Mercati<sup>3</sup>, Mahesh Subedar<sup>3</sup>, Yian Ma<sup>1</sup>, Rose Yu<sup>1</sup>, Tajana Rosing<sup>1</sup> (<sup>1</sup>University of California - San Diego, <sup>2</sup>Illinois Institute of Technology, <sup>3</sup>Intel). ID: 10</li>
                <li>Anonymous. ID: 11</li>
                <li>"<strong><a href="https://drive.google.com/file/d/1lYuRiT5ZZTxCarAvzxZxsvqdD571pJ1J/view?usp=sharing" target="_blank">PromptV: Leveraging LLM-Powered Multi-Agent Prompt Learning for High-Quality Verilog Generation</a></strong>," Zhendong Mi<sup>1</sup>, Renming Zheng<sup>1</sup>, Haowen Zhong<sup>2</sup>, Yue Sun<sup>3</sup>, Shaoyi Huang<sup>1</sup> (<sup>1</sup>Stevens Institute of Technology, <sup>2</sup>University of Washington, <sup>3</sup>Lehigh University). ID: 12</li>
                <li>"<strong><a href="https://drive.google.com/file/d/13aOGIMWtQRDWx1KsMuVDbWUD_cH4v-7O/view?usp=sharing" target="_blank">LLM-VeriPPA: Power, Performance, and Area-aware Verilog Code Generation and Refinement with Large Language Models</a></strong>," Kiran Thorat<sup>1</sup>, Jiahui Zhao<sup>1</sup>, Amit Hasan<sup>1</sup>, Yaotian Liu<sup>2</sup>, Xi Xie<sup>1</sup>, Hongwu Peng<sup>1</sup>, Bin Lei<sup>1</sup>, Jeff Zhang<sup>2</sup>, Caiwen Ding<sup>3</sup> (<sup>1</sup>University of Connecticut, <sup>2</sup>Arizona State University, <sup>3</sup>University of Minnesota). ID: 13</li>
                <li>"<strong><a href="https://drive.google.com/file/d/1ynlaoTQnSfIKQivGwVs-dYKTy46rX7Ww/view?usp=sharing" target="_blank">Simulator Generation via Large Language Models: A Custom Programming Interface Approach</a></strong>," Jihoon Hong, Hyewon Suh, Yonggan Fu, Yingyan (Celine) Lin (Georgia Institute of Technology). ID: 14</li>
                <li>"<strong><a href="https://drive.google.com/file/d/1nkwBcxUV0oMW4DbM9l_oFeNRAEvlH_pi/view?usp=sharing" target="_blank">Balor with Merlin Compiler: Exploiting Diversity of Kernel Representation and Multi-Dataset Learning</a></strong>," Emmet Murphy, Lana Josipovic (ETH Zürich). ID: 15</li>
                <li>"<strong><a href="https://drive.google.com/file/d/1p4JnQBVzF4GE3AF6crZUFnItUVAa0uxu/view?usp=sharing" target="_blank">VeriDPO: Exploring Alignment for Verilog Designs</a></strong>," Daniel Kiesewalter, Luca Valente, Andrea Bonetti, Malte J. Rasch, Lorenzo Servadei (Sony AI). ID: 16</li>
                <li>"<strong><a href="https://drive.google.com/file/d/1v1dMHS0-VS92Zg-kD6e7njbzsfBZFOfC/view?usp=sharing" target="_blank">PVT-Goal: Solving PVT-Aware Transistor Sizing Problem with Goal-Conditioned Reinforcement Learning Framework</a></strong>," Seunggeun Kim, David Z. Pan (The University of Texas at Austin). ID: 17</li>
                <li>"<strong><a href="https://drive.google.com/file/d/1oiRIAAipPTzlS0-hSr2AoeL3vAq67AtH/view?usp=sharing" target="_blank">Agentic-HLS: An Agentic Reasoning Based High-Level Synthesis System Using Large Language Models</a></strong>," Ali Emre Oztas, Zheyu Liu, Mahdi Jelodari (The University of Manchester). ID: 18</li>
                <li>Anonymous. ID: 19</li>
                <li>"<strong><a href="https://drive.google.com/file/d/1rFusoc5D0Px7wjPDvAB6CduXVHmrWHSt/view?usp=sharing" target="_blank">An Efficient Transformer and Genetic Algorithm Based HLS Design Space Exploration</a></strong>," Yujie Yan, Guanhua Chen, Chang Wu (Fudan University). ID: 20</li>
                <li>"<strong><a href="https://drive.google.com/file/d/1MbXblji3nlp-nQ5JIUlVHW-EQzkSmMO1/view?usp=sharing" target="_blank">MAGE: A Multi-Agent Engine for Automated RTL Code Generation</a></strong>," Yujie Zhao, Hejia Zhang, Hanxian Huang, Zhongming Yu, Jishen Zhao (University of California San Diego). ID: 21</li>
            </ul>
        </section>
    </main>
</body>

</html>
