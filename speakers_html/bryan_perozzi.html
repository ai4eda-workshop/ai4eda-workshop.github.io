<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Bryan Perozzi</title>
    <link rel="stylesheet" href="../styles/schedule.css"> <!-- Link to the same CSS -->
</head>

<body>
    <header class="header">
        <nav class="navbar">
            <ul>
                <li><a href="../index.html">Overview</a></li>
                <li><a href="../schedule.html">Schedule</a></li>
                <li><a href="../call_for_poster.html">Call for Posters</a></li>
                <li><a href="../contest.html">ML for Chip Design Contest</a></li>
                <li><a href="../photos.html">Event Photos</a></li>
            </ul>
        </nav>
        <div class="title-section">
            <h1>Speaker: Bryan Perozzi</h1>
        </div>
    </header>

    <main class="content">
        <section class="speaker-details">
            <h2>Bryan Perozzi (Google)</h2>
            <img src="../images/bryan_perozzi.jpg" alt="Bryan Perozzi" style="width: 150px; float: left; margin-right: 20px;">
            <h3>Title: Predicting System Performance Characteristics with Graph Machine Learning</h3>

            <h3>Abstract</h3>
            <p>Precise hardware performance models play a crucial role in code optimization for machine learning systems. They can assist compilers in making heuristic decisions or aid autotuners in identifying the optimal configuration for a given program. Recent advances in Graph Machine Learning have made it possible to add the computational graphs of machine learning programs directly to such learned cost models. In this talk, I'll describe our work to improve and deploy these systems. Specifically, I'll cover our development of learned cost models for Tensor Processing Units (TPUs) and a Kaggle contest we ran for an open-source dataset of TPU program graphs. I'll also go over our recent work on graph soft-prompting for large language models and its application to improve few-shot generalization performance in learned cost models.</p>

            <h3>Bio</h3>
            <p>Bryan Perozzi is a Research Scientist in Google Research's Algorithms and Optimization group, whose research focuses on learning expressive representations of graph data with neural networks. Bryan is an author of 40+ peer-reviewed papers at leading conferences in machine learning and data mining (such as NeurIPS, ICML, ICLR, KDD, and WWW). He's the author of popular models in graph representation learning such as DeepWalk (random walk node embeddings), MixHops (graph neural networks), etc. Bryan's current research focuses on the intersection of structured data and generative AI, where he's teaching large language models to 'Talk Like a Graph'.</p>
            <p>Bryan was awarded the ACM SIGKDD 2024 Test of Time Award for his work in advancing neural network representations for graph data in "DeepWalk: Online Learning of Social Representations", and his doctoral thesis won the prestigious ACM SIGKDD Dissertation Award (2017). Bryan received his Ph.D. in Computer Science from Stony Brook University, where he was advised by Steven Skiena. Prior to that, he obtained a M.S. in Computer Science from Johns Hopkins University and a B.S. in Computer Engineering from Virginia Tech.</p>
        </section>
    </main>
</body>

</html>
